# Series

To do:

- definition of sequence
- limit of sequence
- convergence and divergence and plenty of examples
- definition of series as limit of partial sums

## Notation: sequences and series

### Sequences

#### Overview

Your intuition of a sequence will likely be correct.
It can mean a sequence of letters, such as a word (e.g. A, U, S, T, R, A, L, I, A) or a DNA sequence 
(e.g. A, T, G, C, G, G, T, C, A, T, C).
It can also be a sequence of numbers such as a telephone number, date of birth, something nonsensical 
(e.g. $181291, 2, -4309, \sqrt{7}$) or the prime numbers: $2, 3, 5, 7, 11, \dots$.
Here, the dots indicate that the sequence goes on infinitely.

Each part of the sequence is called a **term**.
Each sequence has a specific ordering of terms. 
For example, the series $1,2,3,4$ is different from the series $4,3,2,1$ much in the same way that the telephone number 
$18001234$ will reach a different person to the phone number $18004321$.

#### Sequences as numerical patterns

In this course sequences will be [numerical patterns](https://www.youtube.com/watch?v=vV7C7bXm4VI). 
Much of mathematics is concerned with patterns in both mathematical constructs and nature, the study of sequences 
provides a firm grounding for this endeavour.

A famous pattern that arises in many natural systems is the [Fibonacci sequence](https://en.wikipedia.org/wiki/Fibonacci_number): 
$0, 1, 1, 2, 3, 5, 8, 13, 21, 34, \dots$.
This sequence is generated by starting with the sequence $0,1$ and finding the next number 
in the sequence by adding the two previous numbers together, e.g. $0+1=\mathbf{1}$, $1+1=\mathbf{2}$, $1+2=\mathbf{3}$, 
$2+3=\mathbf{5}$, $3+5=\mathbf{8}$, etc.


#### Definition

```{admonition} Definition
A **sequence** is a set of terms where order matters, written as follows:

```{math}
    u_1, u_2, \dots, u_n
```
Here, the size of the sequence (the number of terms) is $n$.
The $i$-th term in the sequence is $u_i$ where $i = 1, 2, \dots, n$.
It must be noted that the index notation $i$ is an arbitrarily chosen, one might use other letters such as $j$ or $k$
or even Greek letters such as $\alpha$ or $\sigma$.
It is also conventional to express a series in brackets: $(u_1, u_2, \dots, u_n)$.
As we saw in the previous examples, sequences can have finite $n<\infty$ (e.g. telephone numbers) or infinite sizes 
$n \to \infty$ (e.g. Fibonacci sequence and prime numbers).

#### Expressing a sequence pattern as a formula (a recurence relation)

It is sometimes possible to express a sequence as a formula, otherwise known as a 
[recurrence relation](https://en.wikipedia.org/wiki/Recurrence_relation), which sets out the 
rule(s) to find the sequence.
For example, the Fibonacci sequence can be expressed as the formula 
```{math}
u_i=u_{i-1}+u_{i-2}
```
which specifies the $i$-th term provided we have the term for $i-1$ and $i-2$.
It is because of this formula that it is necessary to provide the first two terms of the sequence, $u_1=0$ and $u_2=1$, 
to find the rest of the sequence.
This formula can be used to find the entire, infinite sequence.
For example, the 298-th term is $u_{298} = 84885164052257330097714121751630835360966663883732297726369399$ and
the 299-th term is $u_{299} = 137347080577163115432025771710279131845700275212767467264610201$ and hence the
300-term is is $u_{300} = 222232244629420445529739893461909967206666939096499764990979600$.

Note that the formula $u_i=u_{i-1}+u_{i-2}$ will generate a different sequence to the Fibonacci sequence when the 
starting terms ar different (e.g. $u_1=10$ and $u_2=11$).
For an example, convince yousrelf that the formule $u_i = 2 + u_{i-1}$ provides the sequence of even numbers when
$u_1=2$ and the sequence of odd numbers when $u_1=1$.

As a final example, the formula $u_i = 2 + 3 \times (i-2)$ generates the infinite sequence: $-1, 2, 5, 8, 11, 14, 17, 20, \dots$.
Note that it is not necessary to provide the first term in the sequence because the formula does not depend on the previous
term(s) in the sequence.
Also notice that the sequence grows without bound.
That is, each term is larger than each of the previous terms.
In this way the sequence grows to an infinite value as $i$ tends to infinity.

Recurrance relations, although simple, can produce surprisingly complicated behaviours.
For further reading you may like to study the [logistic map](https://en.wikipedia.org/wiki/Logistic_map):
```{math}
u_{i+1} = r u_{i} (1 - u_i) \ ,
```
where $r$ is a constant.
This equation (which models animal population growth) openned up the field of chaos theory.





### Series

Series play a central role in calculus and are the main reason why we introduce sequences in the section above.

#### Definition

Series are simply defined by the sum of a sequence.
```{admonition} Definition
A **series** is the sum of a sequence of terms, written as follows:


```{math}
\sum_{i=1}^n u_i = u_1 + u_2 + \ldots + u_n.
```
The subscript numbering does not have to start from 1. 
We can also replace the upper value $n$ with $\infty$ for an infinite series.
For example, the series of the infinite sequence $(u_1,u_2,u_3,\dots)$ is $\sum_{i=1}^\infty u_i$.

#### Summations

Character $\Sigma$ is the Greek letter sigma, written in upper case, and is used to mean "sum".
We would read the expression above as "the sum of $u_i$ from $i=1$ to $i=n$".
For example the sum of $i$ from $i=1$ to $i=4$ is $\sum_{i=1}^4 i = 1 + 2 + 3 + 4 = 10$ and the sum of $2 i$ from 
$i=1$ to $i=4$ is $\sum_{i=1}^4 2 i = 2 + 4 + 6 + 8 = 20$.
From this example it should be clear that, in general:
```{math}
\sum_{i=1}^n a u_i = a \sum_{i=1}^n u_i
``` 
where $a$ is a constant number and $u_i$ is a function of $i$ (i.e. a number that changes with the value of $i$).
We note that $\sum_{i=1}^n a + u_i$ does not equal ($\ne$) to $a + \sum_{i=1}^n u_i$. 
For example, $\sum_{i=1}^4 1+i = 2 + 3 + 4 + 5 = 14$.



### Questions

Write the following expressions using as a sum ($\Sigma$ notation) without evaluating the sum:
1. $1 + 5 + 9 + 13 + 17 +21$
2. $64-32+16-8+4-2+1$
3. $\frac{1}{3} + \frac{1}{4} + \frac{1}{5} + \dots + \frac{1}{99} $




## Arithmetic and Geometric Progressions

We now introduce the arithmetic progression (otherwise known as the arithmetic sequence) and the geometric progression 
(otherwise known as the geometric sequence).
These sequences have the nice property that their series can be solved.

### Arithmetic progression 

#### Definition

```{admonition} Arithmetic Progression
An arithmetic progression (otherwise known as an arithmetic sequence) is a sequence of $n$ terms which all have a "common 
difference" $d$, written as follows: 

```{math} 
a, a + d, a + 2d, a + 3d, \dots, a + (n-1) d 
```

where $a$ is an arbitrary number.


Using the notation for sequences in the previous section, the $i$-th term of the arithmetic progression is
$u_i=a+(i-1)d$ for $i=1,2,\dots,n$.
An example is the sequence $3,5,7,9,11,13$ in which the first term is $a=3$, the common difference is $d=2$ and the 
number of terms is $n=6$.
An infinite arithmetic progression is given by the case where $n \to \infty$.


#### Solving the series of arithmetic progessions

Series of arithmetic progessions can be solved (i.e. reduced to a number).
The series (or the sum) $S_n$ of an arithmetic progression $u_i=a+(i-1)d$ is:
```{math}
 S_n = \sum_{i=1}^n u_i = \sum_{i=1}^n a + (i -1 ) d = \frac{n}{2} \big( 2 a + (n - 1) d \big) = \frac{n}{2} (a + L)
```
where $L = a + (n-1) d$ is the last term in the series.

Notice that as $n$ (the number of terms) increases, the terms of arithmetic progessions grow without bound.
That is, as $n$ approaches $\infty$, the arithmetic progession approaches $\infty$ if $d>0$ and approaches $-\infty$ if 
$d<0$.
In these cases we say that the series diverges (more on this later!). 
Infinite arithmetic progressions always diverge, the proof of which can be found via 
[this link](https://math.stackexchange.com/questions/3334553/proof-that-arithmetic-series-diverges)
(although further reading is required!).

#### Proof of the solution of the series of arithmetic progressions

Fromm the equation foor $S_n$ write down the reversed series below the original:
```{math}
S_n = a + (a+d) + (a+2d) + \dots + \Big( a + (n-3) d \Big) + \Big( a + (n-2) d \Big) + \Big( a + (n-1) d \Big) \\
S_n = a + \Big( a + (n-1) d \Big) + \Big( a + (n-2) d \Big) + \Big( a + (n-3) d \Big) + \dots + (a+2d) + (a+d) + a \ .
```
Adding these two expressions gives:
```{math}
2 S_n =  \Big( 2 a + (n-1) d \Big) + \Big( 2 a + (n-1) d \Big) + \dots + \Big( 2 a + (n-1) d \Big) \ .
```
Since there are $n$ terms, this equations simplifies to the final result:
```{math}
S_n =  \frac{n}{2} \Big( 2 a + (n-1) d \Big)  \ .
```
[There is a legend](https://www.americanscientist.org/article/gausss-day-of-reckoning), 
that Gauss (a famous mathematician) used a similar approach as a schoolboy back in the 1780s to find the answer to 
$1+2+\dots+99+100$.


#### Questions

1. How many terms are in the sequence $54, 52, 50,\dots, 18$? 
2. Find the sum of the first 30 terms of the arithmetic progression with the first three terms $3,9,15$.
3. Find the sum of the arithmetic progression with first term 2, last term 10 and common difference 2.
4. Evaluate $\sum_{n=1}^{10} (5n-1)$ and $\sum_{n=100}^{1000} n$ .
5. In an arithmetic progression the 3rd term is 26 and the 8th term is 46. Find the 1st term, the common difference and $S_{50}$.
6. Find the sum of the integers between 1 and 100 which are divisible by 6.



### Geometric Progression 

#### Definition

```{admonition} Geometric Progression
A geometric progression (otherwise known as an geometric sequence) is a sequence of $n$ terms which have "common ratio" 
$r$, written as follows:

```{math}
a, a r, a r^2, a r^3, \dots , a r^{n-1}
```
where $a$ is an arbitrary number.
Using the notation for sequences in the previous section, the $i$-th term of the geometric progression is
$u_i=a r^{i-1}$ for $i=1,2,\dots,n$.
In other words, the next term in the geometric progression can be found by multiplying the previous term by the common
ratio $r$, given by the formula $u_i = r u_{i-1}$ where $u_1=a$.
An example is the sequence $24,‚àí12,6,‚àí3,1.5$ in which the first term is $a=2$, the common ratio is $r=‚àí\frac{1}{2}$ and 
the number of terms is $n=5$.

#### Solving the series of geometric progessions

Like arithmetic progessions, the series of geometric progressions can be solved (i.e. reduced to a number).
The series (or the sum) $S_n$ of a geometric progression $u_i=a r^{i-1}$ is:
```{math}
 S_n = \sum_{i=1}^n u_i = a r^{i -1} = a \frac{1 - r^n}{1-r} 
```

#### Proof of the solution of the series of geometric progressions

Starting from the the definition of the series:
```{math}
S_n = a + a r + a r^2 + \dots + a r^{n-3} + a r^{n-2} + a r^{n-1} = a \Big(1 + r + r^2 + \dots + r^{n-3} + r^{n-2} + 
r^{n-1} \big) \ ,
```
we multiply by $r$:
```{math}
r S_n = a \Big(r + r^2 + r^2 + \dots + r^{n-2} + r^{n-1} + r^{n} \big) \ .
```
Subtracting $r S_n$ from $S_n$ and cancelling the terms provides:
```{math}
 S_n - r S_n = a \Big(1 - r^{n} \big) \ ,
```
which can be rearranged to provide the result.



#### A preliminary introduction to convergence and divergence

The behaviour of a geometric progression for "large" numbers of terms $n$ depends on the value of the common ratio $r$.
This can be deduced by the following reasoning.
If $r > 1$ or $r < -1$ (which is to say that the absolute value $\lvert r \rvert < 1$) then the $i$-th term of the
geometric progression $u_i=a r^{i-1}$ becomes a very large positive or negative number.
In this case we say that the series **diverges**.
Conversely, if $\lvert r \rvert < 1$  then $u_i=a r^{i-1}$ becomes a very small positive or negative number.
In this case we say that the series **converges**.
Thus we conclude that
* if $\lvert r \rvert < 1$ then $S_n$ converges and approaches $\frac{a}{1-r}$ as $n\to \infty$,
* if $\lvert r \rvert > 1$ then $S_n$ diverges and approaches $\infty$ as $n\to \infty$.

#### Questions
1. Find the sum of the first five terms in a geometric progression with first term 27 and common ration is $\frac{2}{3}? 
2. Evaluate $ \sum_{n=1}^\infty 729 \Big(\frac{1}{3} \Big)^{n-1}$.
3. The first term of a geometric progression is $8$. Given that the sum of the first three terms is 38, find the two possible values of the common ratio.
4. A geometric progression has first term $27$ and common ratio of $r=\frac{4}{3}$. Find the least number of terms that the sequence can have if its sum exceeds $550$.
5. By writing the recurring decimal $0.123123123\dots$ as a geometric progression, show that it can be expressed as the fraction \frac{41}{333}.









## Binomial Expansion

Throughout your scientific journey you will likely come across a time where you have to solve an equation like $(x+y)^n$.
We will know describe how you go about such a task and will highlight some interesting mathematical relations.

#### Definition of a binomial

Polynomials are expressions such as $a_0 + a_1 x + a_2 x^2 + a_3 x^3$ where $a_0$, $a_1$, $a_2$ and $a_3$ are the
polynomial coefficients and $x$ is the variable.
They can have multiple variables (e.g. $x$ and $y$) such as $a_0 + a_1 x + a_2 x y + a_3 x y^2$. 
A binomial is a polynomial with two terms (e.g. x + y, x^3 + 1,  4.3 x^5 - 2.2 y, etc).
Binomial expansion refers to the computation of powers of binomials:
```{math}
(x+y)^n
```
where $n$ is a real number.
This is a general way to express a binomial expansion - the expansion of more complicated binomials can be "swapped in" 
for the $x$ and $y$ (e.g. $x\to 10 x^3$ and $y \to \sqrt{17}$).
In this section we will investigate the binomial expansion only for the case where $n$ is a noon-negative integer 
(e.g. $n=0,1,2,3,\dots$).


### The binomial formula

We now set out to calculate the polynomials produced by the expansion of powers of a binomial.

#### Expanding low powers of binomials by hand

It is possible to expand low powers of binomials (i.e. $n=0,1,2,3,4,5$) by hand:
```{math}
(x+y)^0 &= 1 \ , \\
(x+y)^1 &= x+y \ , \\
(x+y)^2 &= (x+y)(x+y) = x^2 + 2 x y + y^2 \ , \\
(x+y)^3 &= (x+y) (x+y)^2 = x^3 + 3 x^2 y + 2 x y^2 + y^3 \ , \\ 
(x+y)^4 &= (x+y) (x+y)^3 = x^4 + 4 x^3 y + 6 x^2 y^2 + 4 x y^3 + y^4 \ , \\ 
(x+5)^5 &= (x+y) (x+y)^4 = x^5 + 5 x^4 y + 10 x^3 y^2 + 10 x^2 y^3 + 5 x y^4 + y^5 \ .
```
You can see symmetry and patterns in the polynomials on the right hand side of the expansions.
For instance, the combined powers of the $x$'s and $y$'s are equal to the power of expansion $n$ and the total number
of terms is $n+1$.
But what is the pattern for the coefficients?
The answer to this is not trivial and is a fundamental sequence of numbers - the binomial coefficients.

#### The binomial coefficient

```{admonition} The binomial coefficient
     
```{math}
 \binom{n}{k} = \frac{n!}{k! (n - k)!} \ .
```
Like the number $\pi$, the binomial coefficient pops up in many unexpected places - particularly in counting problems
(the bread-and-butter of the field of combinatorics).
For example, these numbers were first described in tenth century by Indian mathematician 
[Halayuddha](https://en.wikipedia.org/wiki/Halayudha).
The binomial coefficient is the number of ways, disregarding order, that $k$ objects can be chosen from $n$ objects.
This number $\binom{n}{k}$ can be casually referred to as "n choose k", and can be expressed by $C^n_k$ and hence 
calculators encode the binomial coefficient by the "nCk" button.

#### Pascal's triangle

A very old (first discovers in China in 11th century), but very elegant, way of calculating the binomial coefficients 
can be found using 
[Pascal's triangle](https://en.wikipedia.org/wiki/Pascal%27s_trianglehttps://en.wikipedia.org/wiki/Pascal%27s_triangle).

As an introduction to this section, try to prove the following results:
```{math}
\binom{n+1}{k} &= \binom{n}{k} + \binom{n}{k-1} \\
\binom{n}{0} &= \binom{n}{n} = 1 \ .
```
Hint: use the definition of the binomial coefficent.

These results provides a [recurrence relation](https://en.wikipedia.org/wiki/Recurrence_relation) 
for the coefficients in the binomial expansion.
The method is illustrated in the figure below.
```{figure} pascal.png
---
name: pascal
---
Pascal's triangle: a table of binomial coefficients $\binom{n}{k}$.
```
In Pascal's triangle the left-most and right-most values are initially filled out according to the result 
$\binom{n}{0} = \binom{n}{n} = 1$.
Then, the recursive formula $\binom{n+1}{k} = \binom{n}{k} + \binom{n}{k-1}$ is used to fill out the rest of each row.
The trick is that each value is calculated by adding the two values from the row above that are in the same column and 
the preceding column.

Pascal's triangle provides a quick way of finding binomial coefficients by hand. 
For instance, to compute the expansion of $(x+y)^6$, we can read off the coefficients from the 6th row in Pascal's triangle:
```{math}
(x+y)^6 = x^6 + 6 x^5 y + 15 x^4 y^6 + 20 x^3 y^3 + 15 x^2 y^4 + 6 x y^5 + y^6 \ .
```

#### Short video explanation

[Binomial series and Pascal's triangle](https://www.youtube.com/watch?v=XMriWTvPXHI).


#### Factorials

We breifly note that the "$!$" symbol represents a factorial of an integer number.
A factorial of integer number $n$ is defined as the product of all the numbers from $1$ to $n$: 
$n! = n \times (n-1) \times (n-2) \times \dots \times 2 \times 1$.
The special cases of factorials are $0! =1$ and $1!=1$.
The special cases of the binomial coefficient are thus $\binom{n}{0}= 1$, $\binom{n}{1} = n$, $\binom{n}{n}=1$ and 
$\binom{n}{n-1} = n$.
These examples highlight a nice symmetrical property of the binomial coefficient: $\binom{n}{k} = \binom{n}{n-k}$ (where
$0 \le k \le n$).

#### Statement of the binomial formula

Knowing the binomial coeffient allows us to find the solution to $(x + y)^n$ for all positive integers $n=0,1,2,\dots$.
With much ado the binomial formula is as follows.
```{admonition} The binomial formula
    
```{math}
 (x+y)^n = \sum_{k=0}^n \binom{n}{k} x^k y^{n-k} =  \binom{n}{0} x^0 y^n +  \binom{n}{1} x^1 y^{n-1} + \dots +
 \binom{n}{n-1} x^{n-1} y^{1} + \binom{n}{n} x^n y^0 \ .
```
You are not required to be familiar with 
[the details of its derivation](https://math.stackexchange.com/questions/119480/derivation-of-binomial-coefficient-in-binomial-theorem) 
but do need to be able to apply the formula to compute binomial expansions.
This formula also shows you why $ \binom{n}{k}$ are called binomial coefficients - because they are the coefficients of
the polynomial produce by the expansion of powers of binomials.
Reassure yourself of the utility of this formula by timing yourself expanding $(x+y)^6$ by hand and then by the binomial 
formula.
For further reading you may like to explore the [multinomial theorem](https://en.wikipedia.org/wiki/Multinomial_theorem)
which is a generalisation of the binomial formula to polynomials.


#### Questions
1. Calculate $(x+y)^9$ using the Binomial theorem.
2. Calculate the coefficient of the term in $x^2 y^3$ in the expansion $(2 x - 3)^5$.
3. Find the constant term in the expansion $\big(x^2 - \frac{1}{x} \big)^9$.
4. Expand $(1+x-x^2)^7$ in ascending powers of $x$ up to and including the term in $x^3$.


## Limits

The mathematics of limits is used to describe the behaviour of a function or sequence that is not AT a point, 
but approaching it. 
For example, in the geometric progression we saw that the sequence approaches either a finite number (converges) or
infinite number (diverges) as the number of terms appraoches infinity.
In what comes next, we will be interested in calculating the "limit" of (i) the terms in a sequence $u_k$ as 
$k \to \infty$, and (ii) the value of a function $f(x)$ as $x \to c$ where $c$ can be a finite or infinite number.
We may distinguish the cases where:
* the function and terms in a sequence **diverge** to an infinite value (blow up to $\pm \infty$),
* the function and terms in a sequence **converge** to a finite value.




### Limits of functions

The limits of a function are best illustrated by example.


#### Example 1

We start with a trivial example, by considering the function $f(x) = x^2$ near to the point (2,4). 
```{figure} x_squared.png
---
name: x_squared
---
A plot of $f(x)=x^2$ together with the point $(2,4)$.
```
In this example, it is apparent that we can trace along the $x^2$ curve towards the point, from either direction. 
Mathematically, we say that we can make $f(x)$ arbitrarily close ("as close as you like") to 4 by making $x$ 
sufficiently close to 2. 
We write 
```{math}
\lim_{x \to 2} x^2 = 4
```
and we say that " the limit of $x^2$ as $x$ tends to (approaches) 2 is equal to 4".
In fact, for the squared function, it is clear that 
```{math}
\lim_{x \to c} f(x) = f(c)
```
for all $c$, but we will see that this behaviour does not apply for all functions.

We may also consider the limit of a function $f(x)$ as its argument $x$ becomes "very large". 
For instance, we can say that $\lim_{x\to\infty} x^2 = \infty$ since $x^2$ can be made arbitrarily large by making $x$ 
"big enough". 
For instance, we can make $x^2$ larger than 10^{998} by making $x$ larger than 10^{499}.

We would read the expression by saying: "the limit of $x^2$ as $x$ tends to infinity is infinity", though it does not 
actually reach infinity.


#### Example 2

Whilst the limit of $x^2$ for large $x$ is non-finite, there are other functions which approach a finite value as 
$x \to \infty$, and also functions which approach a non-finite value whilst $x$ remains finite. 
For example, consider the behaviour of $f(x) = \frac{1}{x}$, illustrated in the plot below. 
```{figure} reciprocal_x.png
---
name: reciprocal_x
---
A plot of $f(x)= \frac{1}{x}$.
```
In this case, as $x$ becomes very large, $f(x)$ approaches zero.
We write that
```{math}
\lim_{x \to \infty} \frac{1}{x}&= 0^+ \\
\lim_{x \to - \infty} \frac{1}{x}&= 0^- \ .
```
The $0^+$ and $0^‚àí$ have been used here to indicate that the function "tends to zero from above/below" as $x$ tends to 
positive and negative infinity respectively.

Near to $x=0$, the behaviour of $\frac{1}{x}$ is different to what we have seen so far:
* As $x$ tends to zero from above (from the right), the graph shoots off to positive infinity, but...
* As $x$ tends to zero from below (from the left), the graph shoot off to negative infinity.

#### The one-sided limit

The previous example motivates the idea of a [one-sided limit](https://en.wikipedia.org/wiki/One-sided_limit).
We write that
```{math}
\lim_{x \to 0^+} \frac{1}{x} &= + \infty \\
\lim_{x \to 0^-} \frac{1}{x} &= - \infty \ .
```
Since the left- and right- limits are not the same, then we cannot meaningfully refer to "the limit" without providing 
a direction, so the result for $\lim_{x \to 0} \frac{1}{x}$ is undefined. 
We say that the function is discontinuous at $x = 0$, though it is 
"[piecewise continuous](https://math.stackexchange.com/questions/1968943/whats-the-difference-between-continuous-and-piecewise-continuous-functions)" 
on each of the pieces either side of $x=0$.

Another example of a piecewise continous function is the Heaviside function, which we define as:
```{math}
H(x) = \begin{cases}
1 \ \ &\text{if} \ \ \ x > 0 \\
0 \ \ &\text{if} \ \ \ x < 0 
\end{cases}
```
A plot of this function is shown below. It has a finite jump discontinuity at $x=0$.
```{figure} heaviside.png
---
name: heaviside
---
A plot of the Heaviside function $H(x)$.
```


### Limits of sequences



The limit of a sequence is the value that the terms of a sequence approaches (or tends to) as the number of terms 
approaches infinity, written as $k \to \infty$ if $k$ were the index variable.
```{admonition} The limit of a sequence
For a sequence $(u_1, u_2, u_3, \dots)$, the limit of a sequence is written as   
```{math}
 \lim_{k \to \infty} u_k \ .
```
We say that a number, say $U$, is the limit of a the sequence $(u_1, u_2, u_3, \dots)$ if the numbers of the sequence
$u_k$ approach $U$ as $k\to\infty$.
We say that the limit of the sequence diverges if $\lvert U \rvert =\infty$ and converges if $\lvert U \rvert < \infty$.

It is important to note that similarity between the limits of a sequence and a function.
A function $f(x)$ for real number $x$ will have the same limit as the sequence $u_k = f(k)$ for integer number $k$.
For example $f(x) = x^2$, the limit $\lim_{x \to \infty} f(x) = \infty$ is the same as the limit (infinite) of the 
sequence with terms $u_k = k^2$, $(1, 2, 4, 16, \dots).

The key difference is that when we refer to the limit of a sequence we always mean the limit of the terms $u_k$ as the
numbers of terms go to infinity $k\to\infty$.
This is not the case for the limit of functions where the variable (i.e. $x$) can go to any number.

Consider another example from the previous section, the limit of the infinite sequence with terms 
$u_k = \frac{1}{k}$ for $k=1,2,\dots$:
```{math}
1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \dots 
```
is $0$ in the same way that $\lim{x\to\infty} \frac{1}{x} = \infty$.





### Combinaton of limits


It is useful to know how to solve the limit of combinations of functions (or so called functions of functions) such as
```{math}
&\lim_{x \to c} \Big( f(x) + g(x) \Big) \\
&\lim_{x \to c} f(x) g(x)  \\
&\lim_{x \to c} \frac{f(x)}{g(x)} \ ,
```
where $c$ will can be any number such as $0$, $1$ or $\infty$.

The approach we take to solve these depends on whether the limits of the inidividual functions $\lim_{x \to c} f(x)$ 
and $\lim_{x \to c} g(x)$ are finite or infinite.

#### Functions that tend to finite values: the combination theorem for limits

First consider the case where the limit of all the functions are finite.
If and only if the limits of the individual functions are FINITE then we can use the combination theorem to solve the combination
of functions.
```{admonition} The combination theorem for limits
If the limits $\lim_{x \to c} f(x)$ and $\lim_{x \to c} g(x)$  are **finite** then, 
```{math}
 &\lim_{x \to c} \Big( \alpha f(x) + \beta g(x) \Big) = \alpha \lim_{x \to c} f(x) + \beta \lim_{x \to c} g(x) \ ,\\
&\lim_{x \to c} f(x) g(x) = \lim_{x \to c} f(x) \lim_{x \to c} g(x) \ ,  \\
&\lim_{x \to c} \frac{f(x)}{g(x)} \ ,
```
where $\alpha$ and $\beta$ are constants.
To stress the point again, the combination theorem for limits can only be used if the limit of every function is finite.

As an example, consider the function:
```{math}
\lim_{x \to 0} \frac{x^2}{(x+1)^3 - (x-1)^3} \ . 
```
Since the limits of each of the individual functions are finite: $\lim_{x \to 0} x^2 = 0$, $\lim_{x \to 0} (x+1)^3 = 1$ 
and $\lim_{x \to 0} (x-1)^3 = -1$, we can use first and third statment of the combination theorem to rewrite and solve
the equation as:
```{math}
 \lim_{x \to 0} \frac{x^2}{(x+1)^3 - (x-1)^3} &= \frac{\lim_{x \to 0} x^2}{\lim_{x \to 0} \Big((x+1)^3 - (x-1)^3}\\
 &= \frac{\lim_{x \to 0} x^2}{\lim_{x \to 0} (x+1)^3 - \lim_{x \to 0}(x-1)^3}\\
 & = \frac{0}{1 - (-1)} \\
 & = \frac{0}{2} \\
 & = 0
```
So we can conclude the limit of the function is $0$.


#### Functions that to to infinite values

We now consider the case where the limit of all the individual functions are infinite, such as
$\lim_{x\to \infty} x^2 = \infty$ and $\lim_{x\to 0^-} \frac{1}{x} = -\infty$.

The approach we take can be illustrated by the followinig two examples:

##### Example 1

```{math}
 \lim_{x \to \infty} ( x^2 - x ) \ . 
```
This limit appears to "go like" $\infty - \infty$, so you would be forgiven for thinking this result is zero.
On the other hand, there is a sense in which $x^2$ is "much bigger" than $x$ and so it dominates this expression. 
That is $x^2$ "blows up faster" than $x$ as $x\to \infty$.
Indeed, if you try subsitute a large value of $x$ into the function $(x^2 - x)$ you may infer that function can get 
arbitrarily large by making $x$ sufficiently large.
So this limit appears to be infinity.

Another way to approach this problem is to factorise $(x^2 - x) = x (x-1)$; both $x \to \infty$ and $x-1 \to \infty$  
as $x\to\infty$.


##### Example 2

```{math}
 \lim_{x \to \infty} \frac{x + \sqrt{x + 2} }{4 x} \ .
```
The second limit "goes like" $\frac{\infty}{\infty}$, but the answer is not one.
To solve this limit we consider the behaviour of the numerator and denominator separately.
We note that the function $x$ is "much much" greater than $\sqrt{x + 2}$ for large $x$ (i.e. $x >> \sqrt{x + 2}$) so we 
say that the numerator "goes like" $x$ for large $x$.
The denominator simply "goes like" 4ùë•, so the fraction in the limit "goes like" $ \frac{x}{4 x} = \frac{1}{4}$. 
Again, you may convince yourself of this by taking some large values of $x$ on your calculator - 
though note that your calculator may not be able to handle the ratio if you make the values too large.

Another approach you may take is to simply the function first:
```{math}
 \lim_{x \to \infty} \frac{x + \sqrt{x + 2} }{4 x} &= \frac{1 + \frac{\sqrt{x +2 }}{x} }{4} \\
 & = \frac{1 + \sqrt{ \frac{1}{x} + \frac{2}{x^2}  }}{4} \ .
```
Because $\lim_{x\to\infty} \frac{1}{x} = \lim_{x\to\infty} \frac{2}{x^2} = 0$, we can see we also arrive at the solution
of $\frac{1}{4}$.

As an exercise, convince yourself that the limit:
```{math}
 \lim_{x \to 0} \frac{x + \sqrt{x + 2} }{4 x} = \infty \ .
```




##### Summary

From the 2 examples above we illustrate that the solutions can be found be determing the individual function(s) (which
may be constant values) that dominate in the limit.
It most cases it is useful to simply the equation before tackling the limit.

It must be noted that fractions which "go like" $\frac{\infty}{\infty}$ do not necessarily approach a finite limit. 
For instance, the result $\lim_{x \to \infty} \frac{x+2}{x^2 - x}$ is equal to zero, since the degree of the denominator 
is larger than the degree of the numerator and it dominates. 
That is, the denomiator "blows up faster" than the numerator.



### Questions

Find the following limits:
1. $\lim_{x\to\infty} \frac{x+2}{x^2-2}$.
2. $\lim_{x\to\infty} \frac{x-2}{x+2}$.
3. $\lim_{x \to \infty} \big( \sqrt{x^2-2} - \sqrt{x^2+x} \big)$.



## Method of Differences

The [method of differences](https://www.youtube.com/watch?embed=no&v=AAxES-zFuxQ) provides a way to find a series
(sum of a sequence) by using the difference of similar sums to compute the desired result.

This is best illustrated by example.


### Illustrative example
Say we want to compute the sum:
```{math}
\sum_{r=1}^N r \ .
```
One way to approach this is to consider the following two series:
```{math}
\sum_{r=1}^N r (r+1) &= 1 \times 2 + 2 \times 3 + 3 \times 4 + \dots + (N-1) \times N + N \times (N+1) \\
\sum_{r=1}^N r (r-1) &= 1 \times 0 + 2 \times 1 + 3 \times 2 + \dots + (N-1) \times (N-2) + N \times (N-1) \ . 
```
It can be seen that in general the $n$-th term in the second series is the same as the $(n-1)$-th term in the first 
series. 
Therefore, if we calculate the difference between the two sums, almost all of the terms cancel, to leave:
```{math}
\sum_{r=1}^N \Big( r (r+1) - r (r-1) \Big) = N \times (N-1) \ .
```
Observing that $r (r+1) - r (r-1) = 2 r$ then gives us the following result:
```{math}
 \sum_{r=1}^N r = \frac{N(N+1)}{2} \ .
```
We note that this result could also have been found using the formula for an arithmetic progression with first term 1 
and common difference 1.



### Rewriting the summation index

It is possible to demonstrate the cancellation of terms without writing out the terms in the series. 
Using the example above, we could rewrite:
```{math}
 \sum_{r=1}^N r (r-1) = \sum_{r=0}^{N-1} (r+1) r = 0 + \sum_{r=1}^N r (r+1) - N (N+1) \ ,
```
and therefore:
```{math}
\sum_{r=1}^N \Big( r (r+1) - r (r-1) \Big) = \sum_{r=1}^N  r (r+1) - \sum_{r=1}^N  r (r+1)  + N(N+1)  = N(N+1) \ .
```

In general, rewriting the summation index provides:
```{math}
\sum_{r=1}^N f(r+c) = \sum_{r=1+c}^{N+c} f(r) \ ,
```
where $f(r)$ is an arbitrary function of summation index $r$ and $c$ is a postive integer number.
This can be also used for negative integer values:
```{math}
\sum_{r=1}^N f(r-c) = \sum_{r=1-c}^{N-c} f(r) \ .
```
You will find that this technique can drastically simplify summations we wish to solve.

For example:
```{math}
\sum_{r=1}^N \frac{2^{r+5}}{ \sqrt{r+5}} = \sum_{r=6}^{N+5} \frac{2^{r}}{ \sqrt{r}} \ .
```

For another example, consider the difference between the following two sums:
```{math}
D = \sum_{r=1}^N \frac{e^r}{ (r+1) (r+2) } - \sum_{r=1}^N \frac{e^{r+2}}{(r+3) (r+4)} \ .
```
Notice that the function within summation on the right $\frac{e^{r+2}}{(r+3) (r+4)}$ is the same as that on the left
$\frac{e^r}{ (r+1) (r+2) }$ except that the summation index is greater by a value of 2.
Thus we can rewrite the summation index of the right sum to provide:
```{math}
D = \sum_{r=1}^N \frac{e^r}{ (r+1) (r+2) } - \sum_{r=3}^{N+2} \frac{e^r}{(r+1) (r+2)} \ .
 ```
Now we have the same function of the index $r$ but with different values of the summation index.
To solve the equation we simply "take out" the index values that are not common, i.e. $r=1,2$ on the left sumation
and $r=N+1,N+2$ on the right summation:
```{math}
D & = \frac{e^1}{2\times 3} + \frac{e^2}{ 3 \times 4} + \sum_{r=3}^N \frac{e^r}{ (r+1) (r+2) } - 
\sum_{r=3}^N \frac{e^r}{ (r+1) (r+2) } - \frac{e^{N+1}}{(N+2)\times (N+3)}  - \frac{e^{N+2}}{(N+3)\times (N+4)} \\
&=\frac{e^1}{2\times 3} + \frac{e^2}{ 3 \times 4} - \frac{e^{N+1}}{(N+2)\times (N+3)}  - \frac{e^{N+2}}{(N+3)\times (N+4)} 
```
Note: if you struggle with rewriting the summation index, it's ok to just write out the terms in the series and 
demonstrate the cross-cancellation.
 


### Questions

1. Use the result $r^2 (r+1)^2 - (r-1)^2 r^2 = 4 r^3$ to calculate $\sum_{r = 1}^{N} r^3$.
2. By using partial fractions to rewrite the summand, show the result:
```{math}
\sum_{r = 1}^N \frac{2}{r (r+1) (r+2)} = \frac{1}{n+2} - \frac{1}{n+1} + \frac{1}{2} \ . 
```






## Convergence and Divergence


### Fundamental concept

We have already seen in the sections on geometric progression and method of differences that some series can approach 
a finite value as the number of terms grows infinitely large.
Series of this type are called **convergent**. 
For instance, the series $\sum_{n=1}^N frac{1}{4^n}$ approaches (converges) to $\frac{1}{3}$ as $N$ approaches $\infty$
($N \to \infty$).


On the other hand, the series $\sum_{n=1}^N n$ can be made as big as we like by adding additional terms.
We say that this series **diverges**. 
We may start to understand this behaviour by looking at what happens to the size of the terms in the long run.
In the series $\sum_{n=1}^N n$, the terms in the series are themselves growing, but this growing behaviour is not 
necessary for the series to diverge. 
For instance, in the series $\sum_{n=1}^N \frac{1}{4}$ the terms remain finite, but we can make the sum as big as we 
like by adding more terms; so this series also diverges.

Less obviously, if we look at the series $\sum_{n=1}^N \frac{n^2}{4n^2 + 3 n + 1}$ then it may be shown that the terms 
($\frac{n^2}{4n^2 + 3 n + 1}$) in the series approach as $n \to \infty$. 
This means that in the long run the series starts to resemble$\sum_{n=1}^N \frac{1}{4}$. 
Hence, this series also diverges.

### Preliminary test for divergence

These ideas of the previous section lead us to the following "preliminary test for divergence".
```{admonition} Preliminary test for divergence
If the terms $u_n$ in a series do not approach zero as $n \to \infty$ then the series diverges.
```
Note well that the preliminary test cannot conclusively identify a series as convergent, we require further tests in 
our toolbox.
However it does test whether a series is divergent.

This test should intuitively make sense; if the terms in a infinite sequences diverges then the series (the sum of the
sequence) must also diverge. 
However, the case where the terms in the series approach zero may not match our intuition. 
It is NOT necessarily true that if the terms in the series approach zero then the series will converge.

For example, consider the [harmonic series](https://en.wikipedia.org/wiki/Harmonic_series_(mathematics)) 
```{math}
\sum_{n=1}^N \frac{1}{n} \ .
```
As $n \to \infty$, the denominator of the fraction becomes arbitrarily large and so the fraction shrinks away to zero. 
It may appear, then that the series will converge since in the end we are just adding on a bunch of nothings!
However, a clever re-grouping of the terms shows that the series is divergent. 
[The trick](https://en.wikipedia.org/wiki/Harmonic_series_(mathematics)#Comparison_test), which was proved in 1350 by 
the French Mathematician Nicole Oresme, relies on grouping the terms in the following way:
```{math}
\sum_{n=1}^N \frac{1}{n} = \frac{1}{2} + \Big( \frac{1}{3} + \frac{1}{4} \Big) +
 \Big( \frac{1}{5}  + \frac{1}{6} + \frac{1}{7}  + \frac{1}{8} \Big) + \dots
```
so that each new group has twice as many terms as the previous one.
It can be shown that each group of terms is then bigger than $\frac{1}{2}$, and so the sum must be larger than 
$\sum_{n=1}^\infty \frac{1}{2}$, which diverges.
Hence, this sum also diverges.

On the other hand, the terms in the series $\sum_{n=1}^\infty \frac{1}{4^n}$ approach zero, and this sum converges.
The preliminary test cannot distinguish between these cases, and so further tests are needed to determine the behaviour 
of the sum if the terms approach zero in the long run.
One such test is D'Alembert's ratio test, outined below. 



### D'Alembert's ratio test

#### Prelimaries

[D'Alembert's ratio test](https://en.wikipedia.org/wiki/Ratio_test) (sometimes simply referred to as the "ratio test") 
relies on looking at the **ratio** of terms in the series in the long run. 
Again, denoting the terms in the series by $u_n$, we consider the fraction:
```{math}
\Bigg\lvert \frac{u_{n+1}}{u_n} \Bigg\rvert \ ,
```
which compares the size of each term to the one before it. 
The notation |‚Ä¢| is used for the magnitude (otherwise known as the absolute value, e.g. $\lvert -2 \rvert = 2$) of the 
expression.
As such, we only consider the relative size of the terms in the series. 
f the result is less than 1 then the terms in the series are **shrinking**, whilst if the result is greater than 1 then 
the terms in the series are **growing**.

#### Statement

We look at the behaviour of this ratio in the limit $n \to \infty$, written as:
```{admonition} D'Alembert's ratio test
For the magnitude of the ratio of sucessive terms in a series, 
$\rho = \lim_{n \to \infty} \lvert \frac{u_{n+1}}{u_n} \rvert$, then if:
* $\rho < 1$ then the series converges absolutely,
* $\rho>1$ then the series diverges absolutely,
* $\rho=1$ then the test is inconclusive.
```
Note well that the $n+1$ term is the numerator and the $n$ term is the denominator!

Intuitively, D'Alembert's ratio test tells us that if the terms are shrinking then the series converges and if they 
are growing then the series diverges. 
The test is more powerful than the preliminary test, but is usually a bit harder to apply and so we should use the 
preliminary test first (the clue is in the name!).

The proof of the ratio test (not shown here) relies on comparing the series to a convergent/divergent geometric progression.

Cases where the ratio test is inconclusive will not be dealt with in this course, although there are further tests that 
can be used for such problems. 
One of the most straightforward to use is the [sandwich theorem](https://en.wikipedia.org/wiki/Squeeze_theorem) 
(also known as the "squeeze theorem"), which can be used not only to demonstrate that a series is convergent, but also 
to find upper and lower bounds for the value of the sum or even to find the value of the sum exactly.

[A short video of D'Alembert's ratio test](https://www.youtube.com/watch?v=iy8mhbZTY7g).

#### Example

We will use D'Alembert's ratio test to determine whether $\sum_{k=1}^n \frac{k^2}{k!}$ converges.

Letting $u_k = \frac{k^2}{k!}$, the ratio $\frac{u_{k+1}}{u_k}$ simplifies to:
```{math}
\frac{u_{k+1}}{u_k} &= \frac{(k+1)^2}{k^2} \frac{k!}{(k+1)!} \\
&= \frac{(k+1)^2 k!}{k^2 (k+1) k!} \\
& = \frac{k+1}{k^2} \ .
```
Here we have used the definition of the [factorial](https://en.wikipedia.org/wiki/Factorial) to write $(k+1)! = (k+1) k!$.
By recalling the combination theorem, we have that:
```{math}
\rho = \lim_{k\to\infty} \Bigg\lvert \frac{u_{n+1}}{u_n} \Bigg\rvert = \lim_{k \to \infty} \frac{k+1}{k^2} = 0 \ ,
```
and thus the series converges absolutely.

Note:
1. It is very important to get the algebra correct in the division step. This is often done carelessly and can cost a lot of marks.
2. The limit step is important! We are interested to know what happens to the terms in the series in the long run - i.e. as $n \to \infty$. The limit must be explicitly taken!


#### Questions

Use D'Alembert's ratio test to determine if the following series converges:
1.
```{math}
\sum_{k=1}^n \frac{(2 k)!}{2^k k!}
```
2. 
```{math}
\sum_{k=1}^n \frac{(-1)^k}{k} = 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \dots
```

### Absolute vs conditional convergence

See also Chapter 25 of "The Calculus Story: A Mathematical Adventure" by David Acheson.

D'Alembert's ratio test looks at the absolute value of the ratio to determine whether the terms are growing or decaying 
in size without recourse to their sign. 
This allows us to make a statement about the absolute convergence of the series.

In some of the previous examples that we looked at, all of the terms in the series were the same sign 
(all positive or all negative). 
In this case, we do not need to distinguish between absolute and conditional convergence. 
Looking at the relative size of the terms (as in D'Alembert's ratio test) is usually sufficient to determine the 
convergence properties, and the remaining cases it can be tackled by comparison to another series whose convergence 
properties are known.

But in the case where the signs in the series alternate, the behaviour is much more peculiar/subtle. 
For example, consider the series:
```{math}
\sum_{k=1}^n \frac{(-1)^k}{k} = 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \dots \ ,
```
It can be shown (see later work on Taylor series) that this series converges to the natural logarithm of 2, $\ln(2)$.

However, a regrouping of the terms gives:
```{math}
\sum_{k=1}^n \frac{(-1)^k}{k} &= \Big( 1 - \frac{1}{2} \Big)  - \frac{1}{4} + \Big(\frac{1}{3} - \frac{1}{6}\Big) - \frac{1}{8} + 
\Big( \frac{1}{5} - \frac{1}{10} \Big) - \frac{1}{12} + \dots \\
&= \frac{1}{2} - \frac{1}{4} + \frac{1}{6} - \frac{1}{8} + \frac{1}{10} - \frac{1}{12} \\
&= \frac{1}{2} \Big( 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \dots \Big) \ ,
```
which is half of the original series!

In fact, it can be shown that this series can be made equal to any value by a suitable rearrangement of the terms...

This series is an example of a [conditionally convergent](https://en.wikipedia.org/wiki/Conditional_convergence) series 
-i.e. a series that does not converge absolutely, but can be made to converge to (any) value which depends on the 
arrangement of the terms.

```{admonition} 
If a series is **absolutely convergent** then it will converge to the same value for any rearrangement of the terms. 
If the series is not absolutely convergent, then it may be **conditionally convergent**, in which case it can be summed 
to an arbitrary value (finite or infinite) depending on the arrangement of the terms in the series.
```

[Here is a short video explanation](Riemann's paradox).

In this course we will only look at absolute convergence.


## Solutions for this chapter
